{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# C4.5 (avec le gain d'information, cette implementation est juste pour montrer que l'utilisation du gain d'information a donné des resulats plus efficace que l'utilisation du rapport de gain) - Ce model implementé a l'aide des notions de la programmation orientée objet, puisque je vois que c'est plus facile de comprendre le code et de le modifier (la programation fonctionnelle pour implementer ce type de model rend les choses plus compliquées)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'type']\n",
    "data = seaborn.load_dataset(\"iris\", skiprows=1, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class noeud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        # constructeur\n",
    "        \n",
    "        # pour les noeuds de décision\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        \n",
    "        # pour les noeuds feuilles\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Arbre de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        # constructeur\n",
    "        \n",
    "        # inisialisation de la racine de l'arbre\n",
    "        self.root = None\n",
    "        self.dic = {}\n",
    "        # conditions d'arret\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        # fonction récursive pour construire l'arbre de decision\n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        \n",
    "        # fractionner jusqu'à ce que les conditions d'arrêt soient vrai\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # trouver la meilleure répartition\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # vérifier si le gain d'information est positif\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                # récurrence gauche\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # récurrence droite\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                self.dic[best_split[\"feature_index\"]] = best_split[\"threshold\"]\n",
    "                # retourner le noeud de décision\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "\n",
    "        # Calculer le noeud feuille\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # retourner le noeud feuille\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        # pour trouver la meilleure répartition\n",
    "        \n",
    "        # dictionnaire pour stocker la meilleure part\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        # boucle sur l'ensemble des caractéristiques\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # boucler sur toutes les valeurs des caractéristiques présentes dans les données\n",
    "            for threshold in possible_thresholds:\n",
    "                # obtenir la répartition actuelle\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # vérifier si les enfants ne sont pas nuls\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # calculer le gain d'information\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # mettre à jour la meilleure répartition si nécessaire\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "        # retour meilleure répartition\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        # pour diviser les données\n",
    "        \n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def gain_ratio(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        # fonction permettant de calculer le rapport de gain d'information\n",
    "        \n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "\n",
    "        if weight_l != 0 and weight_l != 0:\n",
    "            info_inter = - weight_l*np.log2(weight_l) - weight_r*np.log2(weight_l)\n",
    "\n",
    "        return gain/info_inter if info_inter else 0\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        # fonction permettant de calculer le gain d'information\n",
    "\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "\n",
    "        return gain\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        # fonction pour calculer l'entropie\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        # Fonction de calcul de l'indice de Gini\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        # pour calculer le nœud de la feuille\n",
    "        \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        # pour imprimer l'arbre\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(col_names[tree.feature_index], \"<=\", tree.threshold, \" | gain ratio: \", tree.info_gain)\n",
    "            print(\"%sleft(true):\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright(false):\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "\n",
    "\n",
    "    def tree_to_dict(self, tree=None):\n",
    "        # pour transformer l'arbre en dictionnaire\n",
    "\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "\n",
    "        feature_name = col_names[tree.feature_index] if tree.feature_index is not None else None\n",
    "\n",
    "        left_tree = self.tree_to_dict(tree.left)\n",
    "        right_tree = self.tree_to_dict(tree.right)\n",
    "\n",
    "        if feature_name is not None:\n",
    "            return {feature_name: {f'<={tree.threshold}': {'left (true)': left_tree, 'right (false)': right_tree}}}\n",
    "        else:\n",
    "            # Il s'agit du nœud feuille\n",
    "            return tree.value\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # pour former l'arbre\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "        self.dic = self.tree_to_dict()\n",
    "\n",
    "    def predict(self, X):\n",
    "        # fonction de prédiction d'un nouvel ensemble de données\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        # pour prédire un seul point de données\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split en données Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit le model au données Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petal length <= 1.9  | gain ratio:  0.33741385372714494\n",
      " left(true):setosa\n",
      " right(false):petal width <= 1.5  | gain ratio:  0.427106638180289\n",
      "  left(true):petal length <= 4.9  | gain ratio:  0.05124653739612173\n",
      "    left(true):versicolor\n",
      "    right(false):virginica\n",
      "  right(false):petal length <= 5.0  | gain ratio:  0.019631171921475288\n",
      "    left(true):sepal width <= 2.8  | gain ratio:  0.20833333333333334\n",
      "        left(true):virginica\n",
      "        right(false):versicolor\n",
      "    right(false):virginica\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "classifier.fit(X_train,Y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'petal length': {'<=1.9': {'left (true)': 'setosa', 'right (false)': {'petal width': {'<=1.5': {'left (true)': {'petal length': {'<=4.9': {'left (true)': 'versicolor', 'right (false)': 'virginica'}}}, 'right (false)': {'petal length': {'<=5.0': {'left (true)': {'sepal width': {'<=2.8': {'left (true)': 'virginica', 'right (false)': 'versicolor'}}}, 'right (false)': 'virginica'}}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(classifier.dic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du model pour avoir un metric d'evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.9333333333333333"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test) \n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Ici j'est utilisé toutes les données pour avoir un arbre plus complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petal length <= 1.9  | gain ratio:  0.3333333333333334\n",
      " left(true):setosa\n",
      " right(false):petal width <= 1.7  | gain ratio:  0.38969404186795487\n",
      "  left(true):petal length <= 4.9  | gain ratio:  0.08239026063100136\n",
      "    left(true):petal width <= 1.6  | gain ratio:  0.04079861111111116\n",
      "        left(true):versicolor\n",
      "        right(false):virginica\n",
      "    right(false):petal width <= 1.5  | gain ratio:  0.2222222222222222\n",
      "        left(true):virginica\n",
      "        right(false):versicolor\n",
      "  right(false):petal length <= 4.8  | gain ratio:  0.013547574039067499\n",
      "    left(true):sepal length <= 5.9  | gain ratio:  0.4444444444444444\n",
      "        left(true):versicolor\n",
      "        right(false):virginica\n",
      "    right(false):virginica\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "classifier2 = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "classifier2.fit(X, Y)\n",
    "classifier2.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'petal length': {'<=1.9': {'left (true)': 'setosa', 'right (false)': {'petal width': {'<=1.7': {'left (true)': {'petal length': {'<=4.9': {'left (true)': {'petal width': {'<=1.6': {'left (true)': 'versicolor', 'right (false)': 'virginica'}}}, 'right (false)': {'petal width': {'<=1.5': {'left (true)': 'virginica', 'right (false)': 'versicolor'}}}}}}, 'right (false)': {'petal length': {'<=4.8': {'left (true)': {'sepal length': {'<=5.9': {'left (true)': 'versicolor', 'right (false)': 'virginica'}}}, 'right (false)': 'virginica'}}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(classifier2.dic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
