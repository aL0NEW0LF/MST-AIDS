{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# CART (DECISTION TREE REGRESSION) - Ce model implementé a l'aide des notions de la programmation orientée objet, puisque je vois que c'est plus facile de comprendre le code et de le modifier (la programation fonctionnelle pour implementer ce type de model rend les choses plus compliquées)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = seaborn.load_dataset('tips')\n",
    "col_names = data.columns.tolist()\n",
    "col_names.remove('tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class noeud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, var_red=None, value=None):\n",
    "        # constructeur\n",
    "\n",
    "        # pour les noeuds de décision\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.var_red = var_red\n",
    "        \n",
    "        # pour les noeuds feuilles\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        # constructeur\n",
    "\n",
    "        # inisialisation de la racine de l'arbre\n",
    "        self.root = None\n",
    "        self.dic = {}\n",
    "\n",
    "        # conditions d'arret\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        # fonction récursive pour construire l'arbre de decision\n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        best_split = {}\n",
    "        # fractionner jusqu'à ce que les conditions d'arrêt soient vrai\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # trouver la meilleure répartition\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # vérifier si le gain d'information est positif\n",
    "            if best_split[\"var_red\"]>0:\n",
    "                # récurrence gauche\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # récurrence droite\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                # retourner le noeud de décision\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
    "                            left_subtree, right_subtree, best_split[\"var_red\"])\n",
    "        \n",
    "        # Calculer le noeud feuille\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # retourner le noeud feuille\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        # pour trouver la meilleure répartition\n",
    "        \n",
    "        # dictionnaire pour stocker la meilleure part\n",
    "        best_split = {}\n",
    "        max_var_red = -float(\"inf\")\n",
    "\n",
    "        # boucle sur l'ensemble des caractéristiques\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # boucler sur toutes les valeurs des caractéristiques présentes dans les données\n",
    "            for threshold in possible_thresholds:\n",
    "                # obtenir la répartition actuelle\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # vérifier si les enfants ne sont pas nuls\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # calculer la variance intra-groupe\n",
    "                    curr_var_red = self.variance_reduction(y, left_y, right_y)\n",
    "                    # mettre à jour la meilleure répartition si nécessaire\n",
    "                    if curr_var_red>max_var_red:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"var_red\"] = curr_var_red\n",
    "                        max_var_red = curr_var_red\n",
    "                        \n",
    "        # retourer meilleure répartition\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        # pour diviser les données\n",
    "        \n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def variance_reduction(self, parent, l_child, r_child):\n",
    "        # fonction permettant de calculer la variance intra-groupe\n",
    "        \n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        reduction = np.var(parent) - (weight_l * np.var(l_child) + weight_r * np.var(r_child))\n",
    "        return reduction\n",
    "    \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        # pour calculer le nœud de la feuille\n",
    "        \n",
    "        val = np.mean(Y)\n",
    "        return val\n",
    "                \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        # pour imprimer l'arbre\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            if isinstance(tree.threshold, float):\n",
    "                print(col_names[tree.feature_index], \"<=\", tree.threshold, \" | gain ratio\", tree.var_red)\n",
    "            else:\n",
    "                print(col_names[tree.feature_index], \"->\", tree.threshold, \" | gain ratio\", tree.var_red)\n",
    "            print(\"%sleft (true):\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright (false):\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "\n",
    "    def tree_to_dict(self, tree=None):\n",
    "        # pour transformer l'arbre en dictionnaire\n",
    "\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "\n",
    "        feature_name = col_names[tree.feature_index] if tree.feature_index is not None else None\n",
    "\n",
    "        left_tree = self.tree_to_dict(tree.left)\n",
    "        right_tree = self.tree_to_dict(tree.right)\n",
    "\n",
    "        if feature_name is not None:\n",
    "            if isinstance(tree.threshold, float):\n",
    "                return {feature_name: {f'<={tree.threshold}': {'left (true)': left_tree, 'right (false)': right_tree}}}\n",
    "            else:\n",
    "                return {feature_name: {tree.threshold: {'left (true)': left_tree, 'right (false)': right_tree}}}\n",
    "        else:\n",
    "            # Il s'agit du nœud feuille\n",
    "            return tree.value\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # pour former l'arbre\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "        self.dic = self.tree_to_dict()\n",
    "        \n",
    "    def make_prediction(self, x, tree):\n",
    "        # pour prédire un seul point de données\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # fonction de prédiction d'un nouvel ensemble de données\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split en données Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, [col for col in range(data.shape[1]) if col != 1]].values\n",
    "Y = data.iloc[:, 1].values.reshape(-1, 1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit le model au données Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_bill <= 20.45  | gain ratio 0.6335364363128835\n",
      " left (true):total_bill <= 16.27  | gain ratio 0.16350535284516765\n",
      "  left (true):total_bill <= 13.81  | gain ratio 0.04675673437500033\n",
      "    left (true):total_bill <= 5.75  | gain ratio 0.033146260683760476\n",
      "        left (true):1.0\n",
      "        right (false):1.9640384615384616\n",
      "    right (false):day -> Sat  | gain ratio 0.12595238095238093\n",
      "        left (true):2.718571428571429\n",
      "        right (false):2.006666666666667\n",
      "  right (false):smoker -> No  | gain ratio 0.04996230670776791\n",
      "    left (true):total_bill <= 16.29  | gain ratio 0.028722773946360136\n",
      "        left (true):3.71\n",
      "        right (false):2.765862068965517\n",
      "    right (false):total_bill <= 16.32  | gain ratio 0.09963669421487614\n",
      "        left (true):4.3\n",
      "        right (false):3.2020000000000004\n",
      " right (false):total_bill <= 45.35  | gain ratio 0.881903970548394\n",
      "  left (true):size -> 3  | gain ratio 0.22224944056438378\n",
      "    left (true):sex -> Female  | gain ratio 0.09893555555555622\n",
      "        left (true):3.9859999999999998\n",
      "        right (false):3.2474999999999996\n",
      "    right (false):smoker -> No  | gain ratio 0.2507772282876326\n",
      "        left (true):4.773888888888889\n",
      "        right (false):3.741818181818182\n",
      "  right (false):total_bill <= 48.27  | gain ratio 1.7050888888888882\n",
      "    left (true):6.73\n",
      "    right (false):9.5\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(min_samples_split=3, max_depth=3)\n",
    "regressor.fit(X_train,Y_train)\n",
    "regressor.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_bill': {'<=20.45': {'left (true)': {'total_bill': {'<=16.27': {'left (true)': {'total_bill': {'<=13.81': {'left (true)': {'total_bill': {'<=5.75': {'left (true)': 1.0, 'right (false)': 1.9640384615384616}}}, 'right (false)': {'day': {'Sat': {'left (true)': 2.718571428571429, 'right (false)': 2.006666666666667}}}}}}, 'right (false)': {'smoker': {'No': {'left (true)': {'total_bill': {'<=16.29': {'left (true)': 3.71, 'right (false)': 2.765862068965517}}}, 'right (false)': {'total_bill': {'<=16.32': {'left (true)': 4.3, 'right (false)': 3.2020000000000004}}}}}}}}}, 'right (false)': {'total_bill': {'<=45.35': {'left (true)': {'size': {3: {'left (true)': {'sex': {'Female': {'left (true)': 3.9859999999999998, 'right (false)': 3.2474999999999996}}}, 'right (false)': {'smoker': {'No': {'left (true)': 4.773888888888889, 'right (false)': 3.741818181818182}}}}}}, 'right (false)': {'total_bill': {'<=48.27': {'left (true)': 6.73, 'right (false)': 9.5}}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(regressor.dic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du model pour avoir un metric d'evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.1184175011994184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y_pred = regressor.predict(X_test)\n",
    "print(f\"MSE: {np.sqrt(mean_squared_error(Y_test, Y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
